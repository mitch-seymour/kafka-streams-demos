// general application config
application.cleanup.onstart = false
application.cleanup.onstart = ${?RESET_STATE}

// delivery api
delivery.api.url = "https://mercury.delivery.mailchimp.com"
delivery.api.key = ${?DELIVERY_API_URL}

delivery.api.key = ""
delivery.api.key = ${?DELIVERY_API_KEY}

// active queue ID store
store.type = "rocksdb"
store.type = ${?STORE_TYPE}

// redis
redis.server = "localhost:6379"
redis.server = ${?REDIS_SERVER}
redis.keys.ttl.seconds = 604800 // 7 days

// elasticsearch sink. the date-based destination index is constructed from
// this value and appended to output records
elasticsearch.index.campaigns = "mta-logs-consumer-campaigns"

// topics
topic.source = "mta-logs"
topic.source = ${?TOPIC_SOURCE}

topic.campaigns = "mta-logs-campaigns"
topic.campaigns = ${?TOPIC_CAMPAIGNS}

topic.intermediate = "mta-logs-rekeyed"
topic.intermediate = ${?TOPIC_INTERMEDIATE}

// kafka streams
kafka.streams.application.id = "mta-logs-consumer-dev"
kafka.streams.application.id = ${?KAFKA_STREAMS_APPLICATION_ID}

kafka.streams.bootstrap.servers = "127.0.0.1:9092"
kafka.streams.bootstrap.servers = ${?KAFKA_STREAMS_BOOTSTRAP_SERVERS}

kafka.streams.cache.max.bytes.buffering = 0 // send aggregations down-stream immediately

kafka.streams.commit.interval.ms = 10000
kafka.streams.commit.interval.ms = ${?KAFKA_STREAMS_COMMIT_INTERVAL_MS}

kafka.streams.metrics.recording.level=DEBUG
kafka.streams.metrics.sample.window.ms = 30000
kafka.streams.metrics.num.samples = 2

kafka.streams.num.standby.replicas = 0
kafka.streams.num.standby.replicas = ${?KAFKA_STREAMS_STANDBY_REPLICAS}

kafka.streams.num.stream.threads = 1
kafka.streams.num.stream.threads = ${?KAFKA_STREAMS_NUM_THREADS}

kafka.streams.poll.ms = 100
kafka.streams.poll.ms = ${?KAFKA_STREAMS_POLL_MS}

kafka.streams.replication.factor = 1
kafka.streams.replication.factor = ${?KAFKA_STREAMS_REPLICATION_FACTOR}

kafka.streams.request.timeout.ms = 30000
kafka.streams.default.key.serde = "org.apache.kafka.common.serialization.Serdes$StringSerde"
kafka.streams.default.value.serde = "org.apache.kafka.common.serialization.Serdes$StringSerde"
kafka.streams.default.timestamp.extractor = "org.apache.kafka.streams.processor.WallclockTimestampExtractor"

kafka.streams.session.timeout.ms=30000
kafka.streams.session.timeout.ms=${?KAFKA_STREAMS_SESSION_TIMEOUT_MS}

// state-store settings
kafka.streams.state.dir = "/tmp/kafka-streams"
state.stores.in.memory = true
state.stores.in.memory = ${?STATE_STORES_IN_MEMORY}

// if this setting is false, all other RocksDB settings will be ignored
rocksdb.use.config.setter = false
rocksdb.use.config.setter = ${?ROCKSDB_USE_CONFIG_SETTER}
rocksdb.block.cache.size.bytes = 52428800 // 50 * 1024 * 1024
rocksdb.block.size.bytes = 4096
rocksdb.cache.index.and.filter.blocks = true
rocksdb.compression.type = "" // empty (none), snappy, z, bzip2, lz4, lz4hc
rocksdb.max.write.buffer.number = 3
rocksdb.write.buffer.size = 16777216 // 16 * 1024 * 1024

// kafka consumer
kafka.streams.auto.offset.reset = "latest"
kafka.streams.fetch.max.wait.ms = 500
kafka.streams.max.partition.fetch.bytes = 1048576 // 1024 * 1024
kafka.streams.max.poll.records = 500

// kafka producer
kafka.streams.acks = 1 // 0, 1, all
kafka.streams.acks = ${?KAFKA_STREAMS_ACKS}
kafka.streams.compression.type = "snappy" // none, gzip, snappy

// graphite config
graphite.reporting.enabled = false
graphite.reporting.enabled = ${?GRAPHITE_REPORTING_ENABLED}

graphite.carbon.host = "127.0.0.1"
graphite.carbon.host = ${?GRAPHITE_CARBON_HOST}

graphite.carbon.port = 2003
graphite.carbon.port = ${?GRAPHITE_CARBON_PORT}

graphite.metrics.prefix = "mta-logs-consumer.test"
graphite.metrics.prefix = ${?GRAPHITE_NAMESPACE}.${?HOSTNAME}

graphite.poll.period.seconds = 30
graphite.poll.period.seconds = ${?GRAPHITE_POLL_PERIOD_SECONDS}

// zabbix config
zabbix.reporting.enabled = false
zabbix.reporting.enabled = ${?ZABBIX_REPORTING_ENABLED}

zabbix.host = "127.0.0.1" // 10.130.64.90
zabbix.host = ${?ZABBIX_HOST}

zabbix.port = 10051
zabbix.port = ${?ZABBIX_PORT}

zabbix.data.host = "" // the host we are collecting data for
zabbix.data.host = ${?ZABBIX_DATA_HOST}

zabbix.poll.period.seconds = 30
zabbix.poll.period.seconds = ${?ZABBIX_POLL_PERIOD_SECONDS}

